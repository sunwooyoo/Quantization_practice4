{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Keras MNIST PQT/QAT Tutorial**"
      ],
      "metadata": {
        "id": "lMIBf4ZxS-uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load tensorflow library"
      ],
      "metadata": {
        "id": "BKC7tS2XTqUq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ3sjxOjSLcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bcc4707-8412-4d1a-bf0c-5d0ecf69f5ca"
      },
      "source": [
        "import os \n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "!pip install tensorflow_model_optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.7/dist-packages (0.7.3)\n",
            "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (0.1.7)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorflow_model_optimization) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/Colab Embedded2022'"
      ],
      "metadata": {
        "id": "YlQPbAAFI-ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e8cec1-6915-4433-ef6e-a398548b72c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset (MNIST)"
      ],
      "metadata": {
        "id": "MgRyj5wmT3Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()\n"
      ],
      "metadata": {
        "id": "c4E2FoIUTLSr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing dataset"
      ],
      "metadata": {
        "id": "_GzFOOZQUDQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], *input_shape)\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test.reshape(x_test.shape[0], *input_shape)\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = tf.one_hot(y_train.astype(np.int32), depth=10)\n",
        "y_test = tf.one_hot(y_test.astype(np.int32), depth=10)\n"
      ],
      "metadata": {
        "id": "Z7s5Q0ueTS7q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and train the baseline model "
      ],
      "metadata": {
        "id": "u6euAfwxUYtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "reg = tf.keras.regularizers.l2(1e-4)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', input_shape=input_shape, kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPooling2D(),    \n",
        "\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg),    \n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg),    \n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    \n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=reg)\n",
        "])\n",
        "\n",
        "schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=1e-3, decay_steps=x_train.shape[0] * epochs // batch_size)\n",
        "\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=schedule, decay=0),\n",
        "            loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "\n",
        "#history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch = len(x_train) / batch_size, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "bPgRbwDBUIZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666ade8b-46ae-440a-faca-4d245db0ad06"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "781/781 [==============================] - 43s 40ms/step - loss: 1.4161 - acc: 0.4962 - val_loss: 1.3339 - val_acc: 0.5223\n",
            "Epoch 2/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 1.1057 - acc: 0.6152 - val_loss: 1.6758 - val_acc: 0.4857\n",
            "Epoch 3/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 1.0046 - acc: 0.6543 - val_loss: 1.6221 - val_acc: 0.5192\n",
            "Epoch 4/50\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.9333 - acc: 0.6829 - val_loss: 1.1327 - val_acc: 0.6291\n",
            "Epoch 5/50\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.8765 - acc: 0.7051 - val_loss: 1.0186 - val_acc: 0.6566\n",
            "Epoch 6/50\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.8342 - acc: 0.7204 - val_loss: 1.2728 - val_acc: 0.6243\n",
            "Epoch 7/50\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.7995 - acc: 0.7358 - val_loss: 0.9025 - val_acc: 0.7085\n",
            "Epoch 8/50\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.7628 - acc: 0.7526 - val_loss: 0.9334 - val_acc: 0.7088\n",
            "Epoch 9/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.7395 - acc: 0.7593 - val_loss: 0.9197 - val_acc: 0.7153\n",
            "Epoch 10/50\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.7226 - acc: 0.7645 - val_loss: 1.0626 - val_acc: 0.6810\n",
            "Epoch 11/50\n",
            "781/781 [==============================] - 30s 39ms/step - loss: 0.7029 - acc: 0.7731 - val_loss: 0.8399 - val_acc: 0.7361\n",
            "Epoch 12/50\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.6883 - acc: 0.7810 - val_loss: 0.9807 - val_acc: 0.6987\n",
            "Epoch 13/50\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.6782 - acc: 0.7840 - val_loss: 0.8391 - val_acc: 0.7491\n",
            "Epoch 14/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6620 - acc: 0.7903 - val_loss: 0.7481 - val_acc: 0.7601\n",
            "Epoch 15/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6533 - acc: 0.7939 - val_loss: 0.8761 - val_acc: 0.7339\n",
            "Epoch 16/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6403 - acc: 0.7987 - val_loss: 0.7466 - val_acc: 0.7691\n",
            "Epoch 17/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6336 - acc: 0.8016 - val_loss: 0.8748 - val_acc: 0.7336\n",
            "Epoch 18/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6231 - acc: 0.8050 - val_loss: 0.8204 - val_acc: 0.7539\n",
            "Epoch 19/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6158 - acc: 0.8072 - val_loss: 0.7201 - val_acc: 0.7736\n",
            "Epoch 20/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.6047 - acc: 0.8128 - val_loss: 0.6407 - val_acc: 0.8030\n",
            "Epoch 21/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.6009 - acc: 0.8123 - val_loss: 0.6733 - val_acc: 0.7923\n",
            "Epoch 22/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.5903 - acc: 0.8171 - val_loss: 0.6661 - val_acc: 0.7987\n",
            "Epoch 23/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.5814 - acc: 0.8199 - val_loss: 1.1077 - val_acc: 0.6848\n",
            "Epoch 24/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5797 - acc: 0.8201 - val_loss: 0.7218 - val_acc: 0.7861\n",
            "Epoch 25/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.5669 - acc: 0.8257 - val_loss: 0.7291 - val_acc: 0.7796\n",
            "Epoch 26/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.5645 - acc: 0.8256 - val_loss: 0.6845 - val_acc: 0.7944\n",
            "Epoch 27/50\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.5508 - acc: 0.8300 - val_loss: 0.7119 - val_acc: 0.7872\n",
            "Epoch 28/50\n",
            "781/781 [==============================] - 29s 38ms/step - loss: 0.5489 - acc: 0.8303 - val_loss: 0.6270 - val_acc: 0.8078\n",
            "Epoch 29/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5400 - acc: 0.8341 - val_loss: 0.6325 - val_acc: 0.8086\n",
            "Epoch 30/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5344 - acc: 0.8357 - val_loss: 0.6628 - val_acc: 0.7993\n",
            "Epoch 31/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5284 - acc: 0.8383 - val_loss: 0.6617 - val_acc: 0.7992\n",
            "Epoch 32/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5224 - acc: 0.8411 - val_loss: 0.6527 - val_acc: 0.8042\n",
            "Epoch 33/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.5138 - acc: 0.8438 - val_loss: 0.6172 - val_acc: 0.8126\n",
            "Epoch 34/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5140 - acc: 0.8419 - val_loss: 0.5712 - val_acc: 0.8280\n",
            "Epoch 35/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.5071 - acc: 0.8446 - val_loss: 0.5941 - val_acc: 0.8198\n",
            "Epoch 36/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.5021 - acc: 0.8467 - val_loss: 0.5977 - val_acc: 0.8193\n",
            "Epoch 37/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4952 - acc: 0.8486 - val_loss: 0.6209 - val_acc: 0.8123\n",
            "Epoch 38/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4916 - acc: 0.8501 - val_loss: 0.5919 - val_acc: 0.8199\n",
            "Epoch 39/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4872 - acc: 0.8522 - val_loss: 0.5579 - val_acc: 0.8316\n",
            "Epoch 40/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4854 - acc: 0.8533 - val_loss: 0.5823 - val_acc: 0.8277\n",
            "Epoch 41/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4815 - acc: 0.8534 - val_loss: 0.5596 - val_acc: 0.8302\n",
            "Epoch 42/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4757 - acc: 0.8532 - val_loss: 0.5565 - val_acc: 0.8317\n",
            "Epoch 43/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4731 - acc: 0.8566 - val_loss: 0.5615 - val_acc: 0.8326\n",
            "Epoch 44/50\n",
            "781/781 [==============================] - 29s 37ms/step - loss: 0.4721 - acc: 0.8578 - val_loss: 0.5561 - val_acc: 0.8338\n",
            "Epoch 45/50\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4692 - acc: 0.8577 - val_loss: 0.5531 - val_acc: 0.8323\n",
            "Epoch 46/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4672 - acc: 0.8591 - val_loss: 0.5503 - val_acc: 0.8356\n",
            "Epoch 47/50\n",
            "781/781 [==============================] - 30s 38ms/step - loss: 0.4639 - acc: 0.8600 - val_loss: 0.5551 - val_acc: 0.8331\n",
            "Epoch 48/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4635 - acc: 0.8601 - val_loss: 0.5477 - val_acc: 0.8347\n",
            "Epoch 49/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4626 - acc: 0.8583 - val_loss: 0.5496 - val_acc: 0.8344\n",
            "Epoch 50/50\n",
            "781/781 [==============================] - 28s 36ms/step - loss: 0.4640 - acc: 0.8594 - val_loss: 0.5495 - val_acc: 0.8340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.models.save_model(model, os.path.join(base_path, \"model.h5\"))\n",
        "model.save_weights(os.path.join(base_path, \"model.weight\"))"
      ],
      "metadata": {
        "id": "SuqOMmBZW1sZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model) # path to the SavedModel directory\n",
        "tflite_model = converter.convert()\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Save the model.\n",
        "with open(os.path.join(base_path, 'model.tflite'), 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "R2Iq-lnRXVcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26fd6b21-6683-4547-b8b5-a0f76e1f7ae2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Quantization-aware Training"
      ],
      "metadata": {
        "id": "BRjEbuqmP2m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_model_optimization.quantization.keras import quantize_apply\n",
        "from tensorflow_model_optimization.quantization.keras import quantize_annotate_layer\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 30\n",
        "\n",
        "reg = tf.keras.regularizers.l2(1e-4)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', input_shape=input_shape, kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPooling2D(),    \n",
        "\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', kernel_regularizer=reg),    \n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    quantize_annotate_layer(tf.keras.layers.Conv2D(64, 3, padding='same', kernel_regularizer=reg)),    \n",
        "    quantize_annotate_layer(tf.keras.layers.BatchNormalization()),\n",
        "    quantize_annotate_layer(tf.keras.layers.ReLU()),\n",
        "    \n",
        "    quantize_annotate_layer(tf.keras.layers.GlobalAveragePooling2D()),\n",
        "    quantize_annotate_layer(tf.keras.layers.Flatten()),\n",
        "    quantize_annotate_layer(tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=reg))\n",
        "   ])\n",
        "\n",
        "model.load_weights(os.path.join(base_path, \"model.weight\"))\n",
        "\n",
        "schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=1e-3, decay_steps=x_train.shape[0] * epochs // batch_size)\n",
        "\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "quantized_model = quantize_apply(model)\n",
        "quantized_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=schedule, decay=0),\n",
        "            loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "quantized_model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                   steps_per_epoch = len(x_train) / batch_size, epochs=epochs, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "id": "GPI3q5Jdifb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e918856e-9d11-4ce1-838e-854c30be7ca7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "781/781 [==============================] - 33s 40ms/step - loss: 0.8138 - acc: 0.7516 - val_loss: 0.7769 - val_acc: 0.7571\n",
            "Epoch 2/30\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.6472 - acc: 0.7957 - val_loss: 1.0035 - val_acc: 0.7135\n",
            "Epoch 3/30\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.6299 - acc: 0.8024 - val_loss: 0.8382 - val_acc: 0.7484\n",
            "Epoch 4/30\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.6154 - acc: 0.8070 - val_loss: 0.6822 - val_acc: 0.7917\n",
            "Epoch 5/30\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.6019 - acc: 0.8124 - val_loss: 0.6355 - val_acc: 0.8045\n",
            "Epoch 6/30\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.5993 - acc: 0.8130 - val_loss: 0.7609 - val_acc: 0.7729\n",
            "Epoch 7/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.5905 - acc: 0.8174 - val_loss: 0.7538 - val_acc: 0.7706\n",
            "Epoch 8/30\n",
            "781/781 [==============================] - 32s 42ms/step - loss: 0.5819 - acc: 0.8200 - val_loss: 0.6789 - val_acc: 0.7987\n",
            "Epoch 9/30\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5721 - acc: 0.8261 - val_loss: 0.9836 - val_acc: 0.7159\n",
            "Epoch 10/30\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.5715 - acc: 0.8253 - val_loss: 0.8376 - val_acc: 0.7475\n",
            "Epoch 11/30\n",
            "781/781 [==============================] - 34s 43ms/step - loss: 0.5596 - acc: 0.8301 - val_loss: 0.6703 - val_acc: 0.7952\n",
            "Epoch 12/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.5531 - acc: 0.8317 - val_loss: 0.8211 - val_acc: 0.7613\n",
            "Epoch 13/30\n",
            "781/781 [==============================] - 33s 43ms/step - loss: 0.5467 - acc: 0.8349 - val_loss: 0.7518 - val_acc: 0.7776\n",
            "Epoch 14/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.5322 - acc: 0.8394 - val_loss: 0.6453 - val_acc: 0.8088\n",
            "Epoch 15/30\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.5263 - acc: 0.8406 - val_loss: 0.6439 - val_acc: 0.8086\n",
            "Epoch 16/30\n",
            "781/781 [==============================] - 32s 40ms/step - loss: 0.5177 - acc: 0.8437 - val_loss: 0.6412 - val_acc: 0.8120\n",
            "Epoch 17/30\n",
            "781/781 [==============================] - 34s 44ms/step - loss: 0.5121 - acc: 0.8434 - val_loss: 0.6012 - val_acc: 0.8227\n",
            "Epoch 18/30\n",
            "781/781 [==============================] - 31s 40ms/step - loss: 0.5054 - acc: 0.8491 - val_loss: 0.5828 - val_acc: 0.8262\n",
            "Epoch 19/30\n",
            "781/781 [==============================] - 31s 39ms/step - loss: 0.4955 - acc: 0.8513 - val_loss: 0.5987 - val_acc: 0.8271\n",
            "Epoch 20/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4903 - acc: 0.8510 - val_loss: 0.5770 - val_acc: 0.8330\n",
            "Epoch 21/30\n",
            "781/781 [==============================] - 37s 47ms/step - loss: 0.4811 - acc: 0.8562 - val_loss: 0.5644 - val_acc: 0.8339\n",
            "Epoch 22/30\n",
            "781/781 [==============================] - 35s 44ms/step - loss: 0.4736 - acc: 0.8590 - val_loss: 0.5347 - val_acc: 0.8435\n",
            "Epoch 23/30\n",
            "781/781 [==============================] - 33s 42ms/step - loss: 0.4736 - acc: 0.8589 - val_loss: 0.5793 - val_acc: 0.8300\n",
            "Epoch 24/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4623 - acc: 0.8612 - val_loss: 0.5767 - val_acc: 0.8284\n",
            "Epoch 25/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4623 - acc: 0.8622 - val_loss: 0.5316 - val_acc: 0.8411\n",
            "Epoch 26/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4558 - acc: 0.8632 - val_loss: 0.5394 - val_acc: 0.8417\n",
            "Epoch 27/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4555 - acc: 0.8644 - val_loss: 0.5306 - val_acc: 0.8421\n",
            "Epoch 28/30\n",
            "781/781 [==============================] - 35s 45ms/step - loss: 0.4523 - acc: 0.8660 - val_loss: 0.5318 - val_acc: 0.8436\n",
            "Epoch 29/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4476 - acc: 0.8666 - val_loss: 0.5265 - val_acc: 0.8447\n",
            "Epoch 30/30\n",
            "781/781 [==============================] - 32s 41ms/step - loss: 0.4510 - acc: 0.8657 - val_loss: 0.5287 - val_acc: 0.8442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3009a0add0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(quantized_model) # path to the SavedModel directory\n",
        "\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open(os.path.join(base_path, 'model_quant.tflite'), 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "JBjKfB0zGg2p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7e9503-282e-45f2-dc7b-6ce544ba004c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/convert.py:766: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Float model in Kb:\", os.path.getsize(os.path.join(base_path, \"model.tflite\")) / float(2**10))\n",
        "print(\"Quantized model in Kb:\",  os.path.getsize(os.path.join(base_path, \"model_quant.tflite\")) / float(2**10))\n"
      ],
      "metadata": {
        "id": "JxG55qBiSJ7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed74660-b2b9-403b-a7d2-2e82d1434af4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Float model in Kb: 290.26171875\n",
            "Quantized model in Kb: 183.390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "COrk0WOpSK_a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Js4Vzj2MVJnJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}